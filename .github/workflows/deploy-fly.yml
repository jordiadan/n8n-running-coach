name: Deploy to Fly.io

on:
  workflow_run:
    workflows: ['CI']
    types: [completed]
  workflow_dispatch:

concurrency:
  group: fly-deploy-${{ github.ref }}
  cancel-in-progress: true

env:
  APP: running-coach-n8n

jobs:
  deploy:
    if: >
      (
        github.event_name == 'workflow_run' &&
        github.event.workflow_run.conclusion == 'success' &&
        github.event.workflow_run.event == 'push' &&
        github.event.workflow_run.head_branch == 'main'
      ) || github.event_name == 'workflow_dispatch'
    runs-on: ubuntu-24.04
    permissions:
      contents: read

    env:
      TARGET_REPO: ${{ github.event_name == 'workflow_run' && github.event.workflow_run.head_repository.full_name || github.repository }}
      TARGET_REF: ${{ github.event_name == 'workflow_run' && github.event.workflow_run.head_sha || github.sha }}

    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          repository: ${{ env.TARGET_REPO }}
          ref: ${{ env.TARGET_REF }}
          fetch-depth: 1

      - name: Check required secrets
        env:
          FLY_API_TOKEN: ${{ secrets.FLY_API_TOKEN }}
          N8N_ENCRYPTION_KEY: ${{ secrets.N8N_ENCRYPTION_KEY }}
          N8N_API_KEY: ${{ secrets.N8N_API_KEY }}
        run: |
          set -euo pipefail
          if [ -z "${FLY_API_TOKEN:-}" ]; then
            echo "❌ Missing FLY_API_TOKEN"; exit 1
          fi
          if [ -z "${N8N_ENCRYPTION_KEY:-}" ]; then
            echo "❌ Missing N8N_ENCRYPTION_KEY"; exit 1
          fi
          if [ -z "${N8N_API_KEY:-}" ]; then
            echo "❌ Missing N8N_API_KEY"; exit 1
          fi
          echo "✅ Required secrets present"

      - name: Setup flyctl
        uses: superfly/flyctl-actions/setup-flyctl@master
        with:
          version: latest

      - name: Auth check
        env:
          FLY_API_TOKEN: ${{ secrets.FLY_API_TOKEN }}
        run: flyctl auth whoami

      - name: Stage N8N_ENCRYPTION_KEY on Fly
        env:
          FLY_API_TOKEN: ${{ secrets.FLY_API_TOKEN }}
          N8N_ENCRYPTION_KEY: ${{ secrets.N8N_ENCRYPTION_KEY }}
        run: |
          flyctl secrets set N8N_ENCRYPTION_KEY="$N8N_ENCRYPTION_KEY" --app "$APP" --stage

      - name: Deploy to Fly
        env:
          FLY_API_TOKEN: ${{ secrets.FLY_API_TOKEN }}
        run: |
          flyctl deploy --app "$APP" --config "fly.toml" --remote-only

      - name: Update workflows via n8n API
        env:
          FLY_API_TOKEN: ${{ secrets.FLY_API_TOKEN }}
          N8N_API_KEY: ${{ secrets.N8N_API_KEY }}
        run: |
          set -euo pipefail
          base_api="https://${APP}.fly.dev/api/v1/workflows"

          sanitize_workflow() {
            local src=$1
            local dst=$2
            python3 - "$src" "$dst" <<'PY'
          import json
          import sys
          from pathlib import Path

          src = Path(sys.argv[1])
          dst = Path(sys.argv[2])
          allowed = {"name", "nodes", "connections", "settings", "active"}
          data = json.loads(src.read_text())
          sanitized = {k: data[k] for k in allowed if k in data}
          dst.write_text(json.dumps(sanitized))
          PY
          }

          verify_workflow() {
            local local_path=$1
            local remote_path=$2
            local label=$3
            python3 - "$local_path" "$remote_path" "$label" <<'PY'
          import hashlib
          import json
          import sys
          from pathlib import Path

          local_path = Path(sys.argv[1])
          remote_path = Path(sys.argv[2])
          label = sys.argv[3]
          allowed = {"name", "nodes", "connections", "settings", "active"}
          drop_keys = {"webhookId"}

          def scrub(obj):
              if isinstance(obj, dict):
                  cleaned = {}
                  for k, v in obj.items():
                      if k in drop_keys:
                          continue
                      if k == "credentials" and isinstance(v, dict):
                          cleaned[k] = {name: {} for name in v.keys()}
                          continue
                      cleaned[k] = scrub(v)
                  return cleaned
              if isinstance(obj, list):
                  return [scrub(v) for v in obj]
              return obj

          def normalize_nodes(nodes):
              normalized = []
              for node in nodes:
                  if not isinstance(node, dict):
                      continue
                  node = scrub(node)
                  node.pop("id", None)
                  normalized.append(node)
              normalized.sort(key=lambda item: item.get("name", ""))
              return normalized

          def normalize_connections(connections):
              if not isinstance(connections, dict):
                  return connections
              normalized = {}
              for source, types in connections.items():
                  if not isinstance(types, dict):
                      normalized[source] = types
                      continue
                  normalized_types = {}
                  for conn_type, groups in types.items():
                      if not isinstance(groups, list):
                          normalized_types[conn_type] = groups
                          continue
                      normalized_groups = []
                      for group in groups:
                          if isinstance(group, list):
                              sorted_group = sorted(
                                  (scrub(item) for item in group if isinstance(item, dict)),
                                  key=lambda item: (item.get("node", ""), item.get("type", ""), item.get("index", 0)),
                              )
                              normalized_groups.append(sorted_group)
                          else:
                              normalized_groups.append(group)
                      normalized_types[conn_type] = normalized_groups
                  normalized[source] = normalized_types
              return normalized

          def canonical(obj):
              return json.dumps(obj, sort_keys=True, separators=(",", ":")).encode()

          local = scrub(json.loads(local_path.read_text()))
          remote_raw = json.loads(remote_path.read_text())
          remote = scrub({k: remote_raw[k] for k in allowed if k in remote_raw})

          local["nodes"] = normalize_nodes(local.get("nodes", []))
          remote["nodes"] = normalize_nodes(remote.get("nodes", []))
          local["connections"] = normalize_connections(local.get("connections", {}))
          remote["connections"] = normalize_connections(remote.get("connections", {}))

          local_settings = local.get("settings", {})
          remote_settings = remote.get("settings", {})
          if isinstance(local_settings, dict) and isinstance(remote_settings, dict):
              remote["settings"] = {k: remote_settings.get(k) for k in local_settings.keys()}
              local["settings"] = local_settings

          if hashlib.sha256(canonical(local)).hexdigest() != hashlib.sha256(canonical(remote)).hexdigest():
              print(f"❌ Workflow verification failed for {label}")
              raise SystemExit(1)

          print(f"✅ Workflow verification succeeded for {label}")
          PY
          }

          update_or_create_workflow() {
            local src=$1
            local workflow_id=$2
            local allow_create=$3
            local label=$4
            local payload="/tmp/${label}.update.json"
            local remote="/tmp/${label}.remote.json"
            local response="/tmp/${label}.response.json"
            local api_url="${base_api}/${workflow_id}"
            local status=""

            sanitize_workflow "$src" "$payload"
            echo "Updating ${label} (${workflow_id})"

            for attempt in {1..10}; do
              status=$(curl -s -o "$response" -w "%{http_code}" \
                -X PUT \
                -H "X-N8N-API-KEY: $N8N_API_KEY" \
                -H "Content-Type: application/json" \
                --data-binary @"$payload" \
                "$api_url" || true)
              if [ "$status" = "200" ]; then
                break
              fi
              if [ "$status" = "404" ] && [ "$allow_create" = "1" ]; then
                break
              fi
              echo "⏳ ${label} update attempt $attempt failed (status: $status); retrying in 6s..."
              sleep 6
            done

            if [ "$status" = "404" ] && [ "$allow_create" = "1" ]; then
              echo "ℹ️  ${label} not found; creating via POST"
              status=$(curl -s -o "$response" -w "%{http_code}" \
                -X POST \
                -H "X-N8N-API-KEY: $N8N_API_KEY" \
                -H "Content-Type: application/json" \
                --data-binary @"$payload" \
                "$base_api" || true)
              if [ "$status" != "200" ] && [ "$status" != "201" ]; then
                echo "❌ ${label} create failed (status: $status)"
                cat "$response" || true
                exit 1
              fi
              workflow_id="$(python3 - "$response" "$workflow_id" <<'PY'
          import json
          import sys
          from pathlib import Path

          payload = json.loads(Path(sys.argv[1]).read_text() or "{}")
          print(payload.get("id") or sys.argv[2])
          PY
              )"
              api_url="${base_api}/${workflow_id}"
              echo "✅ ${label} created (id: ${workflow_id})"
            elif [ "$status" != "200" ]; then
              echo "❌ ${label} update failed (status: $status)"
              cat "$response" || true
              exit 1
            else
              echo "✅ ${label} updated"
            fi

            curl -s -o "$remote" \
              -H "X-N8N-API-KEY: $N8N_API_KEY" \
              "$api_url"
            verify_workflow "$payload" "$remote" "$label"
          }

          update_or_create_workflow \
            "workflows/running_coach_workflow.json" \
            "Q9nTNHZ5vUBf58oI" \
            "0" \
            "running_coach_main"

          update_or_create_workflow \
            "workflows/running_coach_feedback_workflow.json" \
            "running-coach-feedback-ingestion" \
            "1" \
            "running_coach_feedback"
